# -*- coding: utf-8 -*-
"""Proyek Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-sSQ7wEkz_9ahCKDsCDfqIW6IjA1SdC2

# Proyek Predictive Analytics: Customer Churn Prediction

Proyek ini bertujuan untuk memprediksi pelanggan yang kemungkinan churn (meninggalkan layanan) pada perusahaan telekomunikasi menggunakan machine learning. Proses prediksi ini akan membantu perusahaan dalam mengembangkan strategi untuk mengurangi churn pelanggan. Dataset yang digunakan berisi data pelanggan yang bisa diakses dari Kaggle, yang meliputi beberapa kolom seperti ID pelanggan, layanan yang digunakan, dan informasi demografis.

Dataset yang digunakan dalam proyek ini diambil dari Kaggle. Dataset ini berisi informasi tentang pelanggan dan layanan yang mereka gunakan.

##1. Data Understanding
Informasi Dataset
- Ukuran Dataset: 7,043 baris dan 21 kolom
- Link Sumber Dataset: [Kaggle Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

Dataset ini berisi kolom-kolom berikut:
- **customerID**: ID unik pelanggan
- **gender**: Jenis kelamin pelanggan
- **SeniorCitizen**: Indikator apakah pelanggan adalah orang tua
- **Partner**: Apakah pelanggan memiliki pasangan
- **Dependents**: Apakah pelanggan memiliki tanggungan
- **tenure**: Lama waktu pelanggan menggunakan layanan
- **PhoneService**: Apakah pelanggan memiliki layanan telepon
- **MultipleLines**: Apakah pelanggan memiliki beberapa sambungan telepon
- **InternetService**: Jenis layanan internet yang digunakan
- **OnlineSecurity, DeviceProtection, TechSupport, StreamingTV, StreamingMovies**: Layanan tambahan yang dimiliki
- **Contract**: Tipe kontrak (bulan ke bulan, satu tahun, dua tahun)
- **PaperlessBilling**: Apakah pelanggan menggunakan penagihan tanpa kertas
- **PaymentMethod**: Metode pembayaran
- **MonthlyCharges**: Biaya bulanan
- **TotalCharges**: Total biaya yang dibayarkan
- **Churn**: Apakah pelanggan meninggalkan layanan (ya/tidak)

##2. Data Preprocessing
Tahap ini meliputi:
1. Import libraries yang akan digunakan pada proyek ini
2. Memuat dataset.
3. Memeriksa informasi awal seperti jumlah baris dan kolom, nilai yang hilang, dan tipe data.
4. Menampilkan distribusi churn pelanggan untuk memperoleh gambaran dasar.
"""

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV

# Load dataset
df = pd.read_csv('Telco-Customer-Churn.csv')
df.head()

"""### Memeriksa Informasi Dataset

Menampilkan informasi umum tentang dataset untuk memastikan tidak ada data yang hilang dan mengidentifikasi tipe data.
"""

# Memeriksa informasi awal dari dataset
print("Informasi Dataset:")
print(df.info())
print("\nStatistik Deskriptif:")
print(df.describe())

# Visualisasi distribusi churn
sns.countplot(x='Churn', data=df)
plt.title('Distribusi Churn')
plt.show()

"""##3. Data Preparation
Sebelum membangun model, tahap ini meliputi:
1. Menangani nilai hilang dengan menggantinya menggunakan median.
2. Menangani outlier pada kolom `MonthlyCharges` dengan metode IQR.
3. Preprocessing data numerik menggunakan `StandardScaler` dan kategorikal menggunakan `OneHotEncoder`.
4. Memisahkan data menjadi fitur (X) dan label (y), serta
5. Membagi dataset menjadi data pelatihan dan pengujian.
"""

# Mengubah kolom `TotalCharges` menjadi numerik dan mengisi missing values dengan median
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)

# Menangani outlier pada kolom `MonthlyCharges` dengan metode IQR
Q1 = df['MonthlyCharges'].quantile(0.25)
Q3 = df['MonthlyCharges'].quantile(0.75)
IQR = Q3 - Q1

# Mendefinisikan batas bawah dan atas
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Mengganti nilai outlier pada `MonthlyCharges` dengan batas atas/bawah
df['MonthlyCharges'] = np.where(df['MonthlyCharges'] < lower_bound, lower_bound, df['MonthlyCharges'])
df['MonthlyCharges'] = np.where(df['MonthlyCharges'] > upper_bound, upper_bound, df['MonthlyCharges'])

# Visualisasi boxplot sebelum dan sesudah penanganan outlier
plt.figure(figsize=(12, 6))

# Boxplot sebelum penanganan outlier
plt.subplot(1, 2, 1)
sns.boxplot(y=df['MonthlyCharges'])
plt.title('Boxplot of MonthlyCharges (Sebelum penanganan outliers)')

# Boxplot setelah penanganan outlier
plt.subplot(1, 2, 2)
sns.boxplot(y=df['MonthlyCharges'])
plt.title('Boxplot of MonthlyCharges (Setelah penanganan outliers)')

plt.tight_layout()
plt.show()

# Visualisasi distribusi sebelum dan sesudah penanganan outlier
plt.figure(figsize=(12, 6))

# Histogram sebelum penanganan outlier
plt.subplot(1, 2, 1)
sns.histplot(df['MonthlyCharges'], bins=30, kde=True)
plt.title('Distribusi MonthlyCharges (Sebelum penanganan outliers)')

# Histogram setelah penanganan outlier
plt.subplot(1, 2, 2)
sns.histplot(df['MonthlyCharges'], bins=30, kde=True)
plt.title('Distribusi MonthlyCharges (Setelah penanganan outliers)')

plt.tight_layout()
plt.show()

# Memisahkan fitur dan target
X = df.drop(columns=['Churn', 'customerID'])
y = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)

# Menentukan kolom kategorikal dan numerik
numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']
categorical_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',
                        'PhoneService', 'MultipleLines', 'InternetService',
                        'OnlineSecurity', 'DeviceProtection', 'TechSupport',
                        'StreamingTV', 'StreamingMovies', 'Contract',
                        'PaperlessBilling', 'PaymentMethod']

print("Numerical Features:", numerical_features)
print("Categorical Features:", categorical_features)

# Preprocessing menggunakan StandardScaler untuk numerik dan OneHotEncoder untuk kategorikal
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(drop='first'), categorical_features)
    ])

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""##4. Modelling dan Evaluasi
## Modelling dan Evaluasi

Pada tahap ini akan menerapkan beberapa algoritma machine learning untuk memprediksi churn pelanggan. Algoritma machine learning yang digunakan yaitu:

- **Logistic Regression**
- **Random Forest**
- **XGBoost**

Setiap model akan dilatih dan dievaluasi menggunakan data pengujian untuk menentukan akurasinya.

"""

# Logistic Regression
model_lr = Pipeline(steps=[('preprocessor', preprocessor),
                             ('classifier', LogisticRegression(max_iter=200))])

model_lr.fit(X_train, y_train)
y_pred_lr = model_lr.predict(X_test)

print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

"""### Logistic Regression

*   Akurasi: 82.11%
*   Precision untuk kelas 0 (tidak churn): 0.86, dan untuk kelas 1 (churn): 0.69.
*   Recall untuk kelas 0: 0.90, dan untuk kelas 1: 0.60.
*   F1-score untuk kelas 1: 0.64.



Model ini cukup baik dalam mengklasifikasikan pelanggan yang tidak churn (kelas 0) dengan akurasi yang tinggi. Namun, performa untuk mengidentifikasi pelanggan yang churn (kelas 1) kurang baik, terlihat dari recall dan F1-score yang lebih rendah. Hal ini menunjukkan bahwa model mungkin tidak cukup sensitif dalam mendeteksi pelanggan yang berisiko meninggalkan layanan.
"""

# Random Forest
model_rf = Pipeline(steps=[('preprocessor', preprocessor),
                             ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42))])

model_rf.fit(X_train, y_train)
y_pred_rf = model_rf.predict(X_test)

print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

"""### Random Forest

* Akurasi: 80.48%
* Precision untuk kelas 0: 0.84, dan untuk kelas 1: 0.68.
* Recall untuk kelas 0: 0.91, dan untuk kelas 1: 0.50.
* F1-score untuk kelas 1: 0.58.

Random Forest menunjukkan akurasi yang sedikit lebih rendah dibandingkan Logistic Regression. Meskipun model ini berhasil mengklasifikasikan pelanggan yang tidak churn dengan baik, tetapi kurang efektif dalam mengidentifikasi churn. Recall untuk kelas 1 sangat rendah (0.50), menunjukkan bahwa banyak pelanggan yang churn tidak terdeteksi.
"""

# XGBoost
model_xgb = Pipeline(steps=[('preprocessor', preprocessor),
                            ('classifier', xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'))])

model_xgb.fit(X_train, y_train)
y_pred_xgb = model_xgb.predict(X_test)

print("\n=== XGBoost ===")
print("Akurasi:", accuracy_score(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))

"""### XGBoost

* Akurasi: 80.41%
* Precision untuk kelas 0: 0.84, dan untuk kelas 1: 0.66.
* Recall untuk kelas 0: 0.90, dan untuk kelas 1: 0.54.
* F1-score untuk kelas 1: 0.59.

Hasil XGBoost mirip dengan Random Forest dengan akurasi yang sedikit lebih rendah. Performa di kelas 1 juga menunjukkan bahwa model ini tidak cukup efektif dalam mengidentifikasi churn.
"""

# Hyperparameter tuning untuk XGBoost
param_grid = {
    'classifier__n_estimators': [50, 100, 200],
    'classifier__max_depth': [3, 5, 7],
    'classifier__learning_rate': [0.01, 0.1, 0.2]
}

grid_search_xgb = GridSearchCV(model_xgb, param_grid, cv=3, scoring='accuracy', n_jobs=-1)
grid_search_xgb.fit(X_train, y_train)

print("Best Parameters for XGBoost:", grid_search_xgb.best_params_)
print("Best Accuracy for XGBoost:", grid_search_xgb.best_score_)

"""Hyperparameter tuning yang telah dilakukan untuk mengoptimalkan kinerja model XGBoost, menghasilkan parameter terbaik sebagai berikut:

- Learning rate: 0.1
- Max depth: 3
- Number of estimators: 50

Meskipun tuning ini memberikan peningkatan akurasi yang kecil, tetap menunjukkan bahwa model ini mirip dengan performa Random Forest, tetapi dengan akurasi yang sedikit lebih rendah. Namun, tantangan utama yang dihadapi adalah efektivitas model dalam mengidentifikasi churn pelanggan, terutama pada kelas 1, di mana recall dan precision masih perlu ditingkatkan.

### Confusion Matrix

Berikut adalah Confusion Matrix untuk setiap model untuk menggambarkan performa prediksi churn pelanggan:
- **Logistic Regression**
- **Random Forest**
- **XGBoost**
"""

# Confusion Matrix untuk Logistic Regression
cm_lr = confusion_matrix(y_test, y_pred_lr)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Logistic Regression')
plt.show()

# Confusion Matrix untuk Random Forest
cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Random Forest')
plt.show()

# Confusion Matrix untuk XGBoost
cm_xgb = confusion_matrix(y_test, y_pred_xgb)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - XGBoost')
plt.show()